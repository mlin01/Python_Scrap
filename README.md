# Financial Data Scraper

A high-performance financial data scraping tool optimized for speed and reliability. Features advanced anti-bot protection bypass and hybrid scraping methods for maximum data extraction success.

## ğŸš€ Key Features

- **Lightning Fast**: 7x faster than traditional methods (39s vs 293s)
- **Anti-Bot Protection**: Automatic AWS WAF challenge resolution
- **Hybrid Approach**: Smart fallback from fast requests to Selenium when needed
- **Terminal Output**: No file creation for maximum speed
- **Financial Focus**: Optimized for Morningstar, Yahoo Finance, and other financial sites

## ğŸ“¦ Installation

1. Clone the project: `git clone <repository-url>`
2. Create virtual environment: `python -m venv venv`
3. Activate virtual environment: `venv\Scripts\activate` (Windows) or `source venv/bin/activate` (Linux/Mac)
4. Install dependencies: `pip install -r requirements.txt`

## ğŸ”¥ Quick Start

### Basic Usage
```powershell
python quick_scraper.py "https://www.morningstar.com/stocks/xnas/aapl/dividends"
```

### Full Content Extraction
```powershell
python quick_scraper.py "https://www.morningstar.com/stocks/xnas/aapl/dividends" full
```

### Batch Processing
```powershell
python quick_scraper.py "https://finance.yahoo.com/quote/AAPL"
python quick_scraper.py "https://www.morningstar.com/stocks/xnas/msft/dividends"
```

## ğŸ“Š Performance Metrics

- **Speed**: 39.64s for complete financial data (vs 293s traditional methods)
- **Success Rate**: 100% with anti-bot protection bypass
- **Data Quality**: Captures JavaScript-rendered content including dividend tables
- **Efficiency**: No file I/O operations for maximum throughput

## ğŸ”§ Advanced Features

### Anti-Bot Protection
- **AWS WAF Challenge Resolution**: Automatic detection and resolution
- **Stealth Browser Configuration**: Hidden automation flags
- **Real Browser Simulation**: Authentic user agent and behavior patterns

### Smart Content Detection
- **Quality Scoring**: Automatic detection of financial data completeness
- **Method Selection**: Intelligent choice between fast and comprehensive methods
- **Fallback Logic**: Seamless switching when fast method insufficient

### Supported Sites
- âœ… **Morningstar**: Dividend data, financial metrics, stock information
- âœ… **Yahoo Finance**: Stock quotes, financial statements
- âœ… **SEC EDGAR**: Company filings and reports
- âœ… **Financial News**: MarketWatch, Bloomberg, Reuters

## ğŸ“ Project Structure

```
financial-scraper/
â”œâ”€â”€ quick_scraper.py          # Main optimized scraper
â”œâ”€â”€ requirements.txt          # Minimal dependencies (5 packages)
â”œâ”€â”€ USAGE.md                 # Comprehensive documentation
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ CLEANUP_SUMMARY.md       # Record of cleanup process
â”œâ”€â”€ .env.example             # Environment configuration template
â”œâ”€â”€ .gitignore               # Git ignore rules
â”œâ”€â”€ logs/                    # Log files directory (auto-created)
â””â”€â”€ output/                  # Output directory (auto-created)
```

## ğŸ“– Documentation

- **[USAGE.md](USAGE.md)**: Comprehensive usage guide with examples
- **[GENERIC_SCRAPER_README.md](GENERIC_SCRAPER_README.md)**: Generic scraper documentation
- **Command line help**: `python quick_scraper.py --help`

### ğŸ› ï¸ Development

### Adding New Sites
1. Modify `quick_scraper.py` directly for new site support
2. Test with the scraper
3. Update documentation

### Contributing
1. Fork the repository
2. Create feature branch
3. Test changes thoroughly  
4. Submit pull request

## ğŸ“Š Dependencies

Only **5 essential packages** required:
- `selenium` - Browser automation for JavaScript sites
- `beautifulsoup4` - HTML parsing
- `requests` - HTTP requests
- `lxml` - XML/HTML processing
- `webdriver-manager` - Automatic ChromeDriver management

## ğŸ“œ License

This project is for educational and research purposes. Please respect website terms of service and robots.txt files.

---

**ğŸš€ Built for speed, designed for reliability, optimized for financial data extraction.**


